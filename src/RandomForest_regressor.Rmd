---
title: "Random Forest Hyperparameter Tuning"
date: "`r Sys.Date()`"
output: pdf_document
toc: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

library(reticulate)

```

# Search for the best hyperparameters

```{python}
import pandas as pd
import numpy as np
from sklearn.metrics import mean_squared_error
from sklearn.ensemble import RandomForestRegressor
from sklearn.model_selection import train_test_split, RandomizedSearchCV


train = pd.read_csv('../data/train_imputed_one_hot_encoded.csv')

X = train.drop(columns=['log_pSat_Pa', 'ID'])
y = train['log_pSat_Pa']

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=100)

rf = RandomForestRegressor()

# number of trees in random forest
n_estimators = [int(x) for x in np.linspace(start=200, stop=2000, num=10)]
# number of features to consider at every split
max_features = ['auto', 'sqrt', 'log2']
# maximum number of levels in tree
max_depth = [int(x) for x in np.linspace(10, 110, num=11)]
max_depth.append(None)
# minimum number of samples required to split a node
min_samples_split = [2, 5, 10]
# minimum number of samples required at each leaf node
min_samples_leaf = [1, 2, 4]
# method of selecting samples for training each tree
bootstrap = [True, False]

grid = {'n_estimators': n_estimators,
        'max_features': max_features,
        'max_depth': max_depth,
        'min_samples_split': min_samples_split,
        'min_samples_leaf': min_samples_leaf,
        'bootstrap': bootstrap}
              
# 10*11*3*3*3*2=5940 

```

## RandomizedSearchCV

```{python}

random_search = RandomizedSearchCV(estimator=rf, param_distributions=grid, n_iter=100, 
cv=5, verbose=2, random_state=100, n_jobs=30)

random_search.fit(X_train, y_train) 

best_params = random_search.best_params_ 

print('Best parameters found: ' , best_params)

```

## GridSearchCV

```{python}

grid_search = GridSearchCV(estimator=rf, param_grid=grid, cv=5, scoring=mse_scorer, n_jobs=-1, verbose=2)

grid_search.fit(X_train, y_train)

best_params = grid_search.best_params_ 

print('Best parameters found: ', best_params)

```

# Running random forest using the best hyperparameters

```{python}

best_rf = RandomForestRegressor(n_estimators=800, 
                                min_samples_split=10, 
                                max_features='sqrt', 
                                max_depth=100,
                                bootstrap=True, 
                                random_state=100)

best_rf.fit(X_train, y_train)


y_test_pred = best_rf.predict(X_test)
y_train_pred = best_rf.predict(X_train)

mse_test = mean_squared_error(y_test, y_test_pred)
mse_train = mean_squared_error(y_train, y_train_pred) 

print('MSE for test: ', mse_test)
print('MSE for train: ', mse_train)

```

# Predict target variable in test data

```{python}

test_real = pd.read_csv('../data/test_imputed_one_hot_encoded.csv')

X_real = test_real.drop(columns=['ID'])


test_real['TARGET'] = y_test_pred

```
